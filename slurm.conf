# THIS FILE IS CONTROLLED BY CFENGINE,
# any local modifications will be overwritten!
# If you want to make changes, please edit the
# master file in: 
#   ocikbgs.uzh.ch:masterfiles/hosts/SLURM.d/etc/slurm-llnl/slurm.conf

# slurm.conf file generated by configurator.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
# 
ControlMachine=slurm0
#ControlAddr=
#BackupController=slurm2
#BackupAddr=192.168.160.6
# 
AuthType=auth/munge
CacheGroups=0
CheckpointType=checkpoint/none 
CryptoType=crypto/munge
#
DisableRootJobs=NO 
#EnforcePartLimits= 
#Epilog=
#PrologSlurmctld=
# 
FirstJobId=1 
MaxJobId=4294901760
#GresTypes= 
#GroupUpdateForce=0
# 
#GroupUpdateTime=600 
#JobCheckpointDir=/var/lib/slurm/checkpoint 
#JobCredentialPrivateKey=
#JobCredentialPublicCertificate=
#
#JobFileAppend=0 
JobRequeue=1 
#JobSubmitPlugins=1 
#KillOnBadExit=0 
#
#Licenses=foo*4,bar 
#MailProg=/usr/bin/mail 
#MaxJobCount=5000 
#MaxStepCount=40000 
#
#MaxTasksPerNode=8 
MpiDefault=openmpi
# Note: Apparently, the `MpiParams` option is needed also for non-mpi
# jobs in slurm 2.5.3.
#MpiParams=ports=12000-12999
#PluginDir= 
#
#PlugStackConfig= 
#PrivateData=jobs 
#ProctrackType=proctrack/linuxproc
#Prolog=
#
#PrologSlurmctld= 
#PropagatePrioProcess=0 
#PropagateResourceLimits= 
#PropagateResourceLimitsExcept= 
PropagateResourceLimitsExcept=MEMLOCK
#
ReturnToService=2
#SallocDefaultCommand= 
SlurmctldPidFile=/var/run/slurm/slurmctld.pid
SlurmctldPort=6817
#
SlurmdPidFile=/var/run/slurm/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/lib/slurm/slurmd
SlurmUser=slurm
#
#SrunEpilog=
#SrunProlog=
StateSaveLocation=/var/lib/slurm/slurmctld
SwitchType=switch/none
#
# TaskEpilog=/site/apps/slurm/bin/task_epilog
# TaskPlugin=task/none
#TaskPluginParam=
# TaskProlog=/site/apps/slurm/bin/task_prolog
#
#TopologyPlugin=topology/tree 
TmpFs=/var/tmp 
#TrackWCKey=no 
#TreeWidth= 
#
#UnkillableStepProgram= 
#UsePAM=0 
# 
# 
# TIMERS 
#BatchStartTimeout=10 
#CompleteWait=0 
#EpilogMsgTime=2000 
#GetEnvTimeout=2 
#HealthCheckInterval=0 
#HealthCheckProgram= 
InactiveLimit=0
KillWait=30
#MessageTimeout=10 
#ResvOverRun=0 
#MinJobAge=300
#OverTimeLimit=0 
SlurmctldTimeout=30
SlurmdTimeout=300
#UnkillableStepTimeout=60 
#VSizeFactor=0 
Waittime=0
# 
# 
# SCHEDULING 
#DefMemPerCPU=0 
FastSchedule=0
#MaxMemPerCPU=0 
#SchedulerRootFilter=1 
#SchedulerTimeSlice=30 
SchedulerType=sched/backfill
SchedulerPort=7321
# NOTE: If we don't know the number of CPUs of each node, we need to
# set FastSchedule=0 and SelectType=select/linear Please check SLURM's
# FAQ and manpage of slurm.conf
# https://computing.llnl.gov/linux/slurm/faq.html#fast_schedule
SelectType=select/linear
SelectTypeParameters=CR_Memory
# 
# 
# JOB PRIORITY 
#PriorityType=priority/basic 
#PriorityDecayHalfLife= 
#PriorityCalcPeriod= 
#PriorityFavorSmall= 
#PriorityMaxAge= 
#PriorityUsageResetPeriod= 
#PriorityWeightAge= 
#PriorityWeightFairshare= 
#PriorityWeightJobSize= 
#PriorityWeightPartition= 
#PriorityWeightQOS= 
# 
# 
# LOGGING AND ACCOUNTING 
#AccountingStorageEnforce=0 
#AccountingStorageHost=
#AccountingStorageLoc=/var/tmp/slurm-acct.txt
#AccountingStoragePass=
#AccountingStoragePort=
#AccountingStorageType=accounting_storage/filetxt
#AccountingStorageUser=
#AccountingStoreJobComment=NO
#ClusterName=gc3cluster
#DebugFlags= 
#JobCompHost=
#JobCompLoc=/var/tmp/slurm-jobs.txt
#JobCompPass=
#JobCompPort=
#JobCompType=jobcomp/filetxt
#JobCompUser=
#JobAcctGatherFrequency=30
#JobAcctGatherType=jobacct_gather/none
SlurmctldDebug=3
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=3
SlurmdLogFile=/var/log/slurm/slurmd.log
#SlurmSchedLogFile= 
#SlurmSchedLogLevel= 
# 
# 
# POWER SAVE SUPPORT FOR IDLE NODES (optional) 
#SuspendProgram= 
#ResumeProgram= 
#SuspendTimeout= 
#ResumeTimeout= 
#ResumeRate= 
#SuspendExcNodes= 
#SuspendExcParts= 
#SuspendRate= 
#SuspendTime= 
# 
# 
# Sockets=1 CoresPerSocket=1 ThreadsPerCore=1
NodeName=cos6_1 
NodeName=cos6_2 
NodeName=cos6_3 
NodeName=cos6_4 
NodeName=cos6_5 
NodeName=cos6_6 
NodeName=cos6_7 
NodeName=cos6_8 
NodeName=cos7_1 
NodeName=cos7_2 
NodeName=cos7_3 
NodeName=cos7_4 
NodeName=cos7_5 
NodeName=cos7_6 
NodeName=cos7_7 
NodeName=cos7_8 
NodeName=u12_1
PartitionName=cos6 Nodes=cos6_1,cos6_2,cos6_3,cos6_4,cos6_5,cos6_6,cos6_7,cos6_8, MaxTime=INFINITE State=UP Default=YES
PartitionName=cos7 Nodes=cos7_1,cos7_2,cos7_3,cos7_4,cos7_5,cos7_6,cos7_7,cos7_8, MaxTime=INFINITE State=UP Default=YES
PartitionName=u12 Nodes=u12_1, MaxTime=INFINITE State=UP Default=YES
